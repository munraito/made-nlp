{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "NLP_Lab01_Poetry_generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn6uqbCaw9Sy"
      },
      "source": [
        "## Lab 01. Poetry generation\n",
        "\n",
        "Let's try to generate some poetry using RNNs. \n",
        "\n",
        "You have several choices here: \n",
        "\n",
        "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
        "\n",
        "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
        "\n",
        "* Some other text source, if it will be approved by the course staff.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading.\n",
        "2. Dictionary generation.\n",
        "3. Data preprocessing.\n",
        "4. Model (neural network) training.\n",
        "5. Text generation (model evaluation).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqUAznJjw9S5"
      },
      "source": [
        "import string\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kJmm2U8w9S6"
      },
      "source": [
        "### Data loading: Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PoEJiHpw9S6"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RLPlzMNAw9S7"
      },
      "source": [
        "if not os.path.exists('sonnets.txt'):\n",
        "    !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/homeworks_basic/Lab2_DL/sonnets.txt\n",
        "\n",
        "with open('sonnets.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "    \n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START : TEXT_END]\n",
        "assert len(text) == 2616"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCJnj64mw9S7"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_idD8tSIw9S7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e0673dc-5566-465f-cd91-5bc9174884fc"
      },
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "text = ''.join([t.lower() for t in text])\n",
        "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
        "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
        "print('OK!')"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XZ_DK0Jw9S8"
      },
      "source": [
        "#### Data loading: \"Евгений Онегин\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWgQ-rOpw9S8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2dab7a9-70f6-4a34-c9ad-e939442ab500"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
        "    \n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "    \n",
        "text = [x.replace('\\t\\t', '') for x in text]"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-19 17:32:57--  https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt’\n",
            "\n",
            "onegin.txt          100%[===================>] 256.37K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-04-19 17:32:57 (6.86 MB/s) - ‘onegin.txt’ saved [262521/262521]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waMvSBobw9S9"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hardE0avw9S-"
      },
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "out = ''.join([t.lower() for t in text])"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmppwgGGw9S-"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UijCZHsTw9S-"
      },
      "source": [
        "tokens = sorted(set(out))"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxj8P2Vjw9S-"
      },
      "source": [
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "HSCTXW8mw9S-"
      },
      "source": [
        "# dict <index>:<char>\n",
        "idx_to_token = {idx: tok for tok,idx in zip(tokens, range(len(tokens)))}\n",
        "\n",
        "# dict <char>:<index>\n",
        "token_to_idx = {tok: idx for tok,idx in zip(tokens, range(len(tokens)))}"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-5d229f65l5",
        "outputId": "7075be48-4864-4d7e-d2eb-b5e6d425a918"
      },
      "source": [
        "len(token_to_idx)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og7bz2VxWcin"
      },
      "source": [
        "# Split to chunks by beginning of new sonnet, filter only long ones, delete unneccesary spaces\n",
        "chunks = text.split('\\n\\n')\n",
        "chunks = [line.strip() for line in chunks if len(line) > 20]\n",
        "chunks = [ch.replace('  ', ' ') for ch in chunks] # .replace('\\n', '')"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiAzVeKq9pp_",
        "outputId": "afd361d2-9212-495e-92fc-ce9f4b0ae88e"
      },
      "source": [
        "chunks[:3]"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"from fairest creatures we desire increase,\\n that thereby beauty's rose might never die,\\n but as the riper should by time decease,\\n his tender heir might bear his memory:\\n but thou, contracted to thine own bright eyes,\\n feed'st thy light's flame with self-substantial fuel,\\n making a famine where abundance lies,\\n thy self thy foe, to thy sweet self too cruel:\\n thou that art now the world's fresh ornament,\\n and only herald to the gaudy spring,\\n within thine own bud buriest thy content,\\n and tender churl mak'st waste in niggarding:\\n  pity the world, or else this glutton be,\\n  to eat the world's due, by the grave and thee.\",\n",
              " \"when forty winters shall besiege thy brow,\\n and dig deep trenches in thy beauty's field,\\n thy youth's proud livery so gazed on now,\\n will be a tatter'd weed of small worth held:\\n then being asked, where all thy beauty lies,\\n where all the treasure of thy lusty days;\\n to say, within thine own deep sunken eyes,\\n were an all-eating shame, and thriftless praise.\\n how much more praise deserv'd thy beauty's use,\\n if thou couldst answer 'this fair child of mine\\n shall sum my count, and make my old excuse,'\\n proving his beauty by succession thine!\\n  this were to be new made when thou art old,\\n  and see thy blood warm when thou feel'st it cold.\",\n",
              " \"look in thy glass and tell the face thou viewest\\n now is the time that face should form another;\\n whose fresh repair if now thou not renewest,\\n thou dost beguile the world, unbless some mother.\\n for where is she so fair whose unear'd womb\\n disdains the tillage of thy husbandry?\\n or who is he so fond will be the tomb,\\n of his self-love to stop posterity?\\n thou art thy mother's glass and she in thee\\n calls back the lovely april of her prime;\\n so thou through windows of thine age shalt see,\\n despite of wrinkles this thy golden time.\\n  but if thou live, remember'd not to be,\\n  die single and thine image dies with thee.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAmmVeM6L250"
      },
      "source": [
        "num_tokens = len(tokens)"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD_3akCyw9S_"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOufsFV4w9S_"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7BeojkIMTm4"
      },
      "source": [
        "import torch, torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import tqdm\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI5YozhTVZNm"
      },
      "source": [
        "def to_matrix(lines, max_len=None, pad=token_to_idx[' '],\n",
        "              dtype=\"int32\", batch_first=True):\n",
        "    \"\"\"Casts a list of texts into RNN-digestable matrix.\"\"\"\n",
        "    max_len = max_len or max(map(len, lines))\n",
        "    lines_ix = np.zeros([len(lines), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(lines)):\n",
        "        line_ix = [token_to_idx[c] for c in lines[i]]\n",
        "        lines_ix[i, :len(line_ix)] = line_ix\n",
        "\n",
        "    if not batch_first:  # convert [batch, time] into [time, batch]\n",
        "        lines_ix = np.transpose(lines_ix)\n",
        "\n",
        "    return lines_ix #, max_len"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9qxvGnGmpSo"
      },
      "source": [
        "class CharRNNCell(nn.Module):\n",
        "    def __init__(self, num_tokens=len(tokens), embedding_size=32,\n",
        "                 rnn_num_units=128):\n",
        "        super(self.__class__, self).__init__()\n",
        "\n",
        "        self.num_units = rnn_num_units\n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
        "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units,\n",
        "                                    rnn_num_units)\n",
        "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next). \n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "\n",
        "        :param x: batch of character ids, containing vector of int64 type\n",
        "        :param h_prev: previous RNN hidden states, containing matrix \n",
        "        [batch, rnn_num_units] of float32 type\n",
        "        \"\"\"\n",
        "        # get vector embedding of x\n",
        "        x_emb = self.embedding(x)\n",
        "\n",
        "        # compute next hidden state using self.rnn_update\n",
        "        x_and_h = torch.cat([h_prev, x_emb], dim=-1)\n",
        "        h_next = self.rnn_update(x_and_h)\n",
        "        h_next = torch.tanh(h_next)\n",
        "\n",
        "        assert h_next.size() == h_prev.size()\n",
        "\n",
        "        # compute logits for the next character probs\n",
        "        logits = self.rnn_to_logits(h_next)\n",
        "\n",
        "        return h_next, F.log_softmax(logits, -1)\n",
        "\n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\"Return RNN state before it processes the first input (h0).\"\"\"\n",
        "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J22vxZGoHXB"
      },
      "source": [
        "def rnn_loop(char_rnn, batch_ix):\n",
        "    \"\"\"\n",
        "    Computes log P(next_character) for all time steps in names_ix.\n",
        "    :param names_ix: an int32 matrix of shape [batch, time], \n",
        "    output of to_matrix(names)\n",
        "    \"\"\"\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    hid_state = char_rnn.initial_state(batch_size)\n",
        "\n",
        "    logprobs = []\n",
        "    for x_t in batch_ix.transpose(0, 1):\n",
        "        hid_state, logp_next = char_rnn(x_t, hid_state)  # single step call\n",
        "        logprobs.append(logp_next)\n",
        "        \n",
        "    return torch.stack(logprobs, dim=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIMZ298nqsRZ"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEpBnguzw9S_"
      },
      "source": [
        "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOjl0oYKqote",
        "outputId": "4ef2bcd0-a608-4435-c879-bc3aa1323cc1"
      },
      "source": [
        "char_rnn = CharRNNCell()\n",
        "criterion = nn.NLLLoss()\n",
        "opt = torch.optim.Adam(char_rnn.parameters(), lr=1e-3)\n",
        "history = []\n",
        "char_rnn"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNNCell(\n",
              "  (embedding): Embedding(38, 32)\n",
              "  (rnn_update): Linear(in_features=160, out_features=128, bias=True)\n",
              "  (rnn_to_logits): Linear(in_features=128, out_features=38, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "XC6cyJLMqoqt",
        "outputId": "23633b09-cc04-40d8-d89a-bb66d9131868"
      },
      "source": [
        "%%time\n",
        "for i in range(1000):\n",
        "    batch_ix = to_matrix(random.sample(chunks, 32))\n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "\n",
        "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
        "\n",
        "    # compute loss\n",
        "    predictions_logp = logp_seq[:, :-1]\n",
        "    actual_next_tokens = batch_ix[:, 1:]\n",
        "\n",
        "    loss = criterion(predictions_logp.contiguous().view(-1, num_tokens),\n",
        "                     actual_next_tokens.contiguous().view(-1))\n",
        "\n",
        "    # train with backprop\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "    history.append(loss.data.numpy())\n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label=\"loss\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 18s, sys: 3.66 s, total: 5min 22s\n",
            "Wall time: 5min 21s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xncn4529w9S_"
      },
      "source": [
        "def generate_sample(char_rnn, seed_phrase=' ', max_length=100,\n",
        "                    temperature=1.0):\n",
        "    \"\"\"\n",
        "    The function generates text given a phrase of length of at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters, the sequence that the RNN \n",
        "    is asked to continue\n",
        "    :param max_length: maximum output length, including seed_phrase length\n",
        "    :param temperature: coefficient for sampling; higher temperature produces \n",
        "    more chaotic outputs, smaller temperature converges to the single \n",
        "    most likely output\n",
        "    \"\"\"\n",
        "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
        "    hid_state = char_rnn.initial_state(batch_size=1)\n",
        "\n",
        "    # feed the seed phrase if there is any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
        "\n",
        "    print(x_sequence[:, -1].shape, hid_state.shape)\n",
        "    # start generating\n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
        "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n",
        "\n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens, p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=-1)\n",
        "\n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdXUybAgHfPe",
        "outputId": "98850d6e-cb2f-4cd8-f945-58de7eb77ab8"
      },
      "source": [
        "# An example of generated text.\n",
        "print(generate_sample(char_rnn, max_length=500, temperature=0.5))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " but, for the sumble state,\n",
            "  and the was in the with thee the true still of thy worth the some beauty the periest be the grace his mady thy beauty in my love thee,\n",
            "    thou where the words on the shall to chalange?\n",
            "  thou the wart unsell his show,\n",
            "  the ear your self so sument that he rest,\n",
            "  which in the world of that and they fire,\n",
            "    the thou my love in fair fallers in my love beauty's beauty berown, and lives shall the full on the gerse the with the sweet and three remear say i of heart th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6rRlWqew9TA"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3Me81fyxpPV"
      },
      "source": [
        "class CharLSTM(nn.Module):\n",
        "    def __init__(self, num_tokens=num_tokens, emb_size=num_tokens,\n",
        "                 num_units=64, num_layers=2, dropout=0.01):\n",
        "        super(self.__class__, self).__init__()\n",
        "\n",
        "        self.num_units = num_units\n",
        "        self.num_layers = num_layers\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.rnn = nn.LSTM(emb_size, num_units, batch_first=True,\n",
        "                           num_layers=num_layers, dropout=dropout)\n",
        "        self.hid_to_logits = nn.Linear(num_units, num_tokens)\n",
        "\n",
        "    def forward(self, x, hid_state = None):\n",
        "        if hid_state is None:\n",
        "            h_seq, _ = self.rnn(self.emb(x))\n",
        "            next_logits = self.hid_to_logits(h_seq)\n",
        "            next_logp = F.log_softmax(next_logits, dim=-1)\n",
        "            return next_logp\n",
        "        else:\n",
        "            h_seq, hid_state = self.rnn(self.emb(x), hid_state)\n",
        "            next_logits = self.hid_to_logits(h_seq)\n",
        "            next_logp = F.log_softmax(next_logits, dim=-1)\n",
        "            return next_logp, hid_state\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        \"\"\"Return RNN state before it processes the first input (h0).\"\"\"\n",
        "        return torch.zeros(self.num_layers, batch_size, self.num_units), torch.zeros(self.num_layers, batch_size, self.num_units)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh11_1Hc0uzZ",
        "outputId": "9a29d2b1-66b3-4b79-c6d2-06197dffe43f"
      },
      "source": [
        "char_lstm = CharLSTM(num_layers=2, num_units=196, dropout=0.05)\n",
        "opt = torch.optim.Adam(char_lstm.parameters(), lr=1e-2)\n",
        "criterion = nn.NLLLoss()\n",
        "history = []\n",
        "char_lstm"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharLSTM(\n",
              "  (emb): Embedding(38, 38)\n",
              "  (rnn): LSTM(38, 196, num_layers=2, batch_first=True, dropout=0.05)\n",
              "  (hid_to_logits): Linear(in_features=196, out_features=38, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpvIKeU2w9TA"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "UeHJh_vaw9TB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "82505915-f0be-4e63-cdb9-3086b6d8a6b0"
      },
      "source": [
        "%%time\n",
        "char_lstm.train()\n",
        "for i in range(1000):\n",
        "    batch_ix = to_matrix(random.sample(chunks, 64))\n",
        "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "\n",
        "    logp_seq = char_lstm(batch_ix)\n",
        "\n",
        "    # compute loss\n",
        "    loss = criterion(logp_seq[:, :-1].contiguous().view(-1, num_tokens),\n",
        "                     batch_ix[:, 1:].contiguous().view(-1))\n",
        "\n",
        "    # train with backprop\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "    history.append(loss.data.numpy())\n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history,label=\"loss\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1h 2min 42s, sys: 1min 5s, total: 1h 3min 47s\n",
            "Wall time: 1h 3min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFx3FHh_6PkP"
      },
      "source": [
        "def generate_sample_lstm(model, seed_phrase=' ', max_length=100,\n",
        "                    temperature=1.0):\n",
        "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
        "    hid_state = model.initial_state(batch_size=1)\n",
        "\n",
        "    # feed the seed phrase if there is any\n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        hid_state, _ = model(x_sequence[:, i], hid_state)\n",
        "\n",
        "    # start generating\n",
        "    for i in range(max_length - len(seed_phrase)):\n",
        "        logp_next, hid_state = model(x_sequence[..., -1:], hid_state)\n",
        "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy().squeeze()\n",
        "        # sample next token and push it back into x_sequence\n",
        "        next_ix = np.random.choice(num_tokens, p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=-1)\n",
        "\n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUHI0YbTw9TB"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gF9o-63gw9TB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45da8f46-cead-442e-98de-0f08a7c2becf"
      },
      "source": [
        "for temp in [0.1, 0.2, 0.5, 1.0, 2.0]:\n",
        "    print(temp, ':')\n",
        "    print(generate_sample_lstm(char_lstm, max_length=500, temperature=temp))"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1 :\n",
            " with presence beauty with melays of laws,\n",
            "  so my sun of your fair that your powerful reasons on that with their habes not then as when first, which makes thy face,\n",
            " on his cheek the treasure of thy amiss,\n",
            " like the defect,\n",
            " they are but dreams beguil'd,\n",
            " which lave and love's breath thou didst forsake me by looking of worth; for compile,\n",
            " or made his adjunct the world must die:\n",
            " the counterforial slave and love knows\n",
            " where thought,\n",
            " in their gazing spent?\n",
            " no marvel thence, be unthough their \n",
            "0.2 :\n",
            " with words must not is my love, to the ear that beauty where thou art more lovely and mutution die.\n",
            "  the breast do thy worst to steal without think of thee, my loss is in my thought,\n",
            " to let us distill'd from limbeckss be travels, and wrow the sun;\n",
            " coral is partly lively new cruel and means comments o'er durs themelled fair, but for my love, and alive this self, that i am, there all men risent repart doth write for my love, knowsh thee in their right, where thou art the wind,\n",
            " or captase eyes\n",
            "0.5 :\n",
            " thou stis sea and land,\n",
            " and putt of beauty set,\n",
            " and you in errswearing the first,\n",
            "  i will not part cor am hath more return fair, as with what is borr were an alle't one hatter words of their servic'd that trustance knowing, only appear.\n",
            " your slave each offending beging unseen,\n",
            " when i saw my way,\n",
            " when that churl doth speak, though doth shames and idle hours nor which should that harvest such cheeks with compare,\n",
            " come in the spring,\n",
            " when i may by and by loving thought:\n",
            " 'hadown with thee \n",
            "1.0 :\n",
            " where cupit be heaven-see's truey desire,\n",
            " ton main o'er rose,\n",
            " when mine some in their well besiege thy looks with sweets to flower before here', will bear lines be true, the painly to make the lays of bittern twain,\n",
            " let, give strange ill,\n",
            " and friend, and thou muse lack.                                                                                                                                                                                                                                 \n",
            "2.0 :\n",
            " may each can mened, and die as fast as th telling love's eye's vongury dend,\n",
            " in , thy hours, andor i say 'to now i ma mort:\n",
            " th trrushion,\n",
            " spy, exemack;\n",
            " ror another eternal gloak,\n",
            " myself i'll famis with moticue depend:\n",
            " \n",
            " wetche with themself with that on the lily'se;\n",
            " now revoling and sims, thy constancy,\n",
            " and keeps your vexe\n",
            " under their witherch beguse untern'. the violet ealane.    the prove,\n",
            "  fleshing 'now thyself-gied, -wish! ho jow time but the part i can a voner's night,\n",
            " i sight t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8S2NfgZJpu6"
      },
      "source": [
        "The bigger temperature coffecient gets, the more chaotic output is. At temp = 2 many words are not even real. And, on the contrary, at the smallest values, words are more primitive and tend to repeat. So, it is better to choose this coefffecient somewhere in the middle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs91QKeJPkFL"
      },
      "source": [
        "Final result is also better than with RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXzvjqIpw9TB"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYxLjuGjw9TB"
      },
      "source": [
        "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qod8hoFqO7MA"
      },
      "source": [
        "torch.save(char_lstm.state_dict(), 'Char_LSTM_Shakespeare.pth')"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcivxUvWD5pZ",
        "outputId": "720dff51-0e35-4702-eade-36f33706346b"
      },
      "source": [
        "loaded_model = CharLSTM(num_layers=2, num_units=196, dropout=0.05)\n",
        "loaded_model.load_state_dict(torch.load('Char_LSTM_Shakespeare.pth'))"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "NE-h_04EPTEU",
        "outputId": "a4206872-6f1a-4a08-ce56-afeeab865919"
      },
      "source": [
        "generate_sample_lstm(loaded_model, max_length=300, temperature=0.7)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"  thou couldst a vengue's rage,\\n withor this blessed in thee aid, so be,\\n making a couplement uside\\n to neven to forty, which pader for my love, thy pine, make me love knows the joy for complicws can set o'er-hway that the parts on the firert,\\n leaves out ornament was idolly veies with cruel; nor tr\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IFz_ieLw9TC"
      },
      "source": [
        "### References\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ]
}